{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-15T14:14:40.873659Z",
     "start_time": "2025-02-15T14:14:33.783423Z"
    }
   },
   "source": [
    "import torch\n",
    "from qadence import QuantumModel, QuantumCircuit\n",
    "\n",
    "\n",
    "class CustomQuantumModel(QuantumModel):\n",
    "\n",
    "    def __init__(self, circuit: QuantumCircuit, observable, backend=\"pyqtorch\", diff_mode=\"ad\"):\n",
    "        super().__init__(circuit, observable=observable, backend=backend, diff_mode=diff_mode)\n",
    "\n",
    "        self.n_qubits = circuit.n_qubits\n",
    "\n",
    "        # define some additional parameters which will scale and shift (variationally) the\n",
    "        # output of the QuantumModel\n",
    "        # you can use all torch machinery for building those\n",
    "        self.scale_out = torch.nn.Parameter(torch.ones(1))\n",
    "        self.shift_out = torch.nn.Parameter(torch.ones(1))\n",
    "\n",
    "    # override the forward pass of the model\n",
    "    # the forward pass is the output of your QuantumModel and in this case\n",
    "    # it's the (scaled) expectation value of the total magnetization with\n",
    "    # a variable coefficient in front\n",
    "    def forward(self, values: dict[str, torch.Tensor]) -> torch.Tensor:\n",
    "\n",
    "        # scale the observable\n",
    "        res = self.expectation(values)\n",
    "\n",
    "        # scale and shift the result before returning\n",
    "        return self.shift_out + res * self.scale_out"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-15T14:14:41.185557Z",
     "start_time": "2025-02-15T14:14:41.118901Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from qadence import Parameter, RX, CNOT, QuantumCircuit\n",
    "from qadence import chain, kron, hamiltonian_factory, Z\n",
    "from sympy import acos\n",
    "\n",
    "def quantum_circuit(n_qubits):\n",
    "\n",
    "    x = Parameter(\"x\", trainable=False)\n",
    "    fm = kron(RX(i, acos(x) * (i+1)) for i in range(n_qubits))\n",
    "\n",
    "    ansatz = kron(RX(i, f\"theta{i}\") for i in range(n_qubits))\n",
    "    ansatz = chain(ansatz, CNOT(0, n_qubits-1))\n",
    "\n",
    "    block = chain(fm, ansatz)\n",
    "    block.tag = \"circuit\"\n",
    "    return QuantumCircuit(n_qubits, block)\n",
    "\n",
    "n_qubits = 4\n",
    "batch_size = 10\n",
    "circuit = quantum_circuit(n_qubits)\n",
    "observable = hamiltonian_factory(n_qubits, detuning=Z)  # Total magnetization\n",
    "\n",
    "model = CustomQuantumModel(circuit, observable, backend=\"pyqtorch\")\n",
    "\n",
    "values = {\"x\": torch.rand(batch_size)}\n",
    "res = model(values)\n",
    "print(\"Model output: \", res)\n",
    "assert len(res) == batch_size"
   ],
   "id": "705bb318429dab66",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model output:  tensor([[ 0.1233],\n",
      "        [ 2.8730],\n",
      "        [-0.1156],\n",
      "        [-0.7156],\n",
      "        [ 1.0020],\n",
      "        [-0.0455],\n",
      "        [ 0.5316],\n",
      "        [ 0.2883],\n",
      "        [-0.6319],\n",
      "        [-0.7759]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Quantum model with wavefunction overlaps",
   "id": "ed2dc94aec271a20"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-15T14:14:41.222940Z",
     "start_time": "2025-02-15T14:14:41.201715Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from qadence import RY, RX, H, Overlap\n",
    "\n",
    "# create a quantum model which acts as an Hadamard gate after training\n",
    "class LearnHadamard(QuantumModel):\n",
    "    def __init__(\n",
    "        self,\n",
    "        train_circuit: QuantumCircuit,\n",
    "        target_circuit: QuantumCircuit,\n",
    "        backend=\"pyqtorch\",\n",
    "    ):\n",
    "        super().__init__(circuit=train_circuit, backend=backend)\n",
    "        self.overlap_fn = Overlap(train_circuit, target_circuit, backend=backend, method=\"exact\", diff_mode='ad')\n",
    "\n",
    "    def forward(self):\n",
    "        return self.overlap_fn()\n",
    "\n",
    "    # compute the wavefunction of the associated train circuit\n",
    "    def wavefunction(self):\n",
    "        return model.overlap_fn.run({})\n",
    "\n",
    "\n",
    "train_circuit = QuantumCircuit(1, chain(RX(0, \"phi\"), RY(0, \"theta\")))\n",
    "target_circuit = QuantumCircuit(1, H(0))\n",
    "\n",
    "model = LearnHadamard(train_circuit, target_circuit)\n",
    "\n",
    "# get the overlap between model and target circuit wavefunctions\n",
    "print(model())"
   ],
   "id": "aecd97c65c1657f0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8049]], grad_fn=<UnsqueezeBackward0>)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-15T14:15:09.666362Z",
     "start_time": "2025-02-15T14:14:44.399849Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from qadence import run\n",
    "from qadence.ml_tools import Trainer, TrainConfig\n",
    "Trainer.set_use_grad(True)\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-1)\n",
    "\n",
    "def loss_fn(model: LearnHadamard, _unused) -> tuple[torch.Tensor, dict]:\n",
    "    loss = criterion(torch.tensor([[1.0]]), model())\n",
    "    return loss, {}\n",
    "\n",
    "config = TrainConfig(max_iter=2500)\n",
    "trainer = Trainer(\n",
    "    model, optimizer, config, loss_fn\n",
    ")\n",
    "model, optimizer = trainer.fit()\n",
    "\n",
    "wf_target = run(target_circuit)\n",
    "assert torch.allclose(wf_target, model.wavefunction(), atol=1e-2)"
   ],
   "id": "cecf0995fe85977",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Output()"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "af3d2bd8c19241fb8503b9b8a0d66243"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/petark/PycharmProjects/venvs/pasqal/lib/python3.12/site-packages/networkx/readwrite/json_graph/node_link.py:142: FutureWarning: \n",
      "The default value will be `edges=\"edges\" in NetworkX 3.6.\n",
      "\n",
      "To make this warning go away, explicitly set the edges kwarg, e.g.:\n",
      "\n",
      "  nx.node_link_data(G, edges=\"links\") to preserve current behavior, or\n",
      "  nx.node_link_data(G, edges=\"edges\") for forward compatibility.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001B[2;36m2025-02-15 15:15:09\u001B[0m\u001B[2;36m \u001B[0m\u001B[34mINFO    \u001B[0m Writing LearnHadamard checkpoint                                       \u001B]8;id=369854;file:///home/petark/PycharmProjects/venvs/pasqal/lib/python3.12/site-packages/qadence/ml_tools/callbacks/saveload.py\u001B\\\u001B[2msaveload.py\u001B[0m\u001B]8;;\u001B\\\u001B[2m:\u001B[0m\u001B]8;id=901389;file:///home/petark/PycharmProjects/venvs/pasqal/lib/python3.12/site-packages/qadence/ml_tools/callbacks/saveload.py#106\u001B\\\u001B[2m106\u001B[0m\u001B]8;;\u001B\\\n",
       "\u001B[2;36m                    \u001B[0m         model_LearnHadamard_ckpt_2500_device_cpu.pt                            \u001B[2m               \u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">2025-02-15 15:15:09 </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Writing LearnHadamard checkpoint                                       <a href=\"file:///home/petark/PycharmProjects/venvs/pasqal/lib/python3.12/site-packages/qadence/ml_tools/callbacks/saveload.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">saveload.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/petark/PycharmProjects/venvs/pasqal/lib/python3.12/site-packages/qadence/ml_tools/callbacks/saveload.py#106\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">106</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         model_LearnHadamard_ckpt_2500_device_cpu.pt                            <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[2;36m                   \u001B[0m\u001B[2;36m \u001B[0m\u001B[34mINFO    \u001B[0m Writing Adam to checkpoint opt_Adam_ckpt_2500_device_cpu.pt            \u001B]8;id=407532;file:///home/petark/PycharmProjects/venvs/pasqal/lib/python3.12/site-packages/qadence/ml_tools/callbacks/saveload.py\u001B\\\u001B[2msaveload.py\u001B[0m\u001B]8;;\u001B\\\u001B[2m:\u001B[0m\u001B]8;id=395393;file:///home/petark/PycharmProjects/venvs/pasqal/lib/python3.12/site-packages/qadence/ml_tools/callbacks/saveload.py#116\u001B\\\u001B[2m116\u001B[0m\u001B]8;;\u001B\\\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Writing Adam to checkpoint opt_Adam_ckpt_2500_device_cpu.pt            <a href=\"file:///home/petark/PycharmProjects/venvs/pasqal/lib/python3.12/site-packages/qadence/ml_tools/callbacks/saveload.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">saveload.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/petark/PycharmProjects/venvs/pasqal/lib/python3.12/site-packages/qadence/ml_tools/callbacks/saveload.py#116\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">116</span></a>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "443223c18a51837e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
