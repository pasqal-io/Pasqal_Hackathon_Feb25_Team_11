{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Data loaders",
   "id": "f9188883934c212"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-15T13:59:57.675483Z",
     "start_time": "2025-02-15T13:59:52.149827Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard x = tensor([[0.0000],\n",
      "        [0.2000]])\n",
      "Standard x = tensor([[0.4000],\n",
      "        [0.6000]])\n",
      "Standard x = tensor([[0.8000],\n",
      "        [1.0000]])\n",
      "Infinite x = tensor([[0.],\n",
      "        [1.]])\n",
      "Infinite x = tensor([[0.8000],\n",
      "        [0.4000]])\n",
      "Infinite x = tensor([[0.6000],\n",
      "        [0.2000]])\n",
      "Infinite x = tensor([[0.],\n",
      "        [1.]])\n",
      "Infinite x = tensor([[0.8000],\n",
      "        [0.4000]])\n",
      "data = {'y1': [tensor([[0.0153],\n",
      "        [0.3496],\n",
      "        [0.8334],\n",
      "        [0.9558],\n",
      "        [0.1501]]), tensor([[0.0153],\n",
      "        [0.3425],\n",
      "        [0.7402],\n",
      "        [0.8168],\n",
      "        [0.1495]])], 'y2': [tensor([[0.1908],\n",
      "        [0.4887],\n",
      "        [0.9825],\n",
      "        [0.9339],\n",
      "        [0.3075]]), tensor([[0.1896],\n",
      "        [0.4695],\n",
      "        [0.8319],\n",
      "        [0.8039],\n",
      "        [0.3027]])]}\n"
     ]
    }
   ],
   "execution_count": 1,
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from qadence.ml_tools import DictDataLoader, to_dataloader\n",
    "\n",
    "\n",
    "def dataloader(data_size: int = 25, batch_size: int = 5, infinite: bool = False) -> DataLoader:\n",
    "    x = torch.linspace(0, 1, data_size).reshape(-1, 1)\n",
    "    y = torch.sin(x)\n",
    "    return to_dataloader(x, y, batch_size=batch_size, infinite=infinite)\n",
    "\n",
    "\n",
    "def dictdataloader(data_size: int = 25, batch_size: int = 5) -> DictDataLoader:\n",
    "    dls = {}\n",
    "    for k in [\"y1\", \"y2\"]:\n",
    "        x = torch.rand(data_size, 1)\n",
    "        y = torch.sin(x)\n",
    "        dls[k] = to_dataloader(x, y, batch_size=batch_size, infinite=True)\n",
    "    return DictDataLoader(dls)\n",
    "\n",
    "\n",
    "# iterate over standard DataLoader\n",
    "for (x, y) in dataloader(data_size=6, batch_size=2):\n",
    "    print(f\"Standard {x = }\")\n",
    "\n",
    "# construct an infinite dataset which will keep sampling indefinitely\n",
    "n_epochs = 5\n",
    "dl = iter(dataloader(data_size=6, batch_size=2, infinite=True))\n",
    "for _ in range(n_epochs):\n",
    "    (x, y) = next(dl)\n",
    "    print(f\"Infinite {x = }\")\n",
    "\n",
    "# iterate over DictDataLoader\n",
    "ddl = dictdataloader()\n",
    "data = next(iter(ddl))\n",
    "print(f\"{data = }\")"
   ],
   "id": "initial_id"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Train configs",
   "id": "7b3926bc3dd871ac"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "| Attribute              | Type                          | Default      | Description                                      |\n",
    "|------------------------|-----------------------------|-------------|--------------------------------------------------|\n",
    "| max_iter              | int                          | 10000       | Total number of training epochs.                |\n",
    "| batch_size           | int                          | 1           | Batch size for training.                        |\n",
    "| print_every          | int                          | 0           | Frequency of console output. Set to 0 to disable. |\n",
    "| write_every          | int                          | 0           | Frequency of logging metrics. Set to 0 to disable. |\n",
    "| plot_every           | int                          | 0           | Frequency of plotting metrics. Set to 0 to disable. |\n",
    "| checkpoint_every     | int                          | 0           | Frequency of saving checkpoints. Set to 0 to disable. |\n",
    "| val_every           | int                          | 0           | Frequency of validation checks. Set to 0 to disable. |\n",
    "| val_epsilon         | float                        | 1e-5        | Threshold for validation improvement.           |\n",
    "| validation_criterion | Callable                     | None        | Function for validating metric improvement.     |\n",
    "| trainstop_criterion | Callable                     | None        | Function to stop training early.                |\n",
    "| callbacks           | list[Callback]               | []          | List of custom callbacks.                       |\n",
    "| root_folder        | Path                          | \"./qml_logs\" | Root directory for saving logs and checkpoints. |\n",
    "| log_folder         | Path                          | \"./qml_logs\" | Logging directory for saving logs and checkpoints. |\n",
    "| log_model          | bool                          | False       | Enables model logging.                          |\n",
    "| verbose            | bool                          | True        | Enables detailed logging.                       |\n",
    "| tracking_tool      | ExperimentTrackingTool       | TENSORBOARD | Tool for tracking training metrics.             |\n",
    "| plotting_functions | tuple                        | ()          | Functions for plotting metrics.                 |\n"
   ],
   "id": "e0e79086e6593ddf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-15T14:01:50.851150Z",
     "start_time": "2025-02-15T14:01:50.844388Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from qadence.ml_tools import OptimizeResult, TrainConfig\n",
    "from qadence.ml_tools.callbacks import Callback\n",
    "\n",
    "batch_size = 5\n",
    "n_epochs = 100\n",
    "\n",
    "print_parameters = lambda opt_res: print(opt_res.model.parameters())\n",
    "condition_print = lambda opt_res: opt_res.loss < 1.0e-03\n",
    "modify_extra_opt_res = {\"n_epochs\": n_epochs}\n",
    "custom_callback = Callback(on=\"train_end\", callback=print_parameters, callback_condition=condition_print,\n",
    "                           modify_optimize_result=modify_extra_opt_res, called_every=10, )\n",
    "\n",
    "config = TrainConfig(\n",
    "    root_folder=\"some_path/\",\n",
    "    max_iter=n_epochs,\n",
    "    checkpoint_every=100,\n",
    "    write_every=100,\n",
    "    batch_size=batch_size,\n",
    "    callbacks=[custom_callback]\n",
    ")\n"
   ],
   "id": "eb3d28315144f357",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Callbacks",
   "id": "561b7d6ccf6aecb5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-15T14:02:54.103337Z",
     "start_time": "2025-02-15T14:02:54.096873Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from qadence.ml_tools.callbacks import Callback\n",
    "\n",
    "\n",
    "def validation_criterion(val_loss: float, best_val_loss: float, val_epsilon: float) -> bool:\n",
    "    return val_loss < (best_val_loss - val_epsilon)\n",
    "\n",
    "\n",
    "def callback_fn(trainer, config, writer):\n",
    "    if trainer.opt_res.loss < 0.001:\n",
    "        print(\"Custom Callback: Loss threshold reached!\")\n",
    "\n",
    "\n",
    "custom_callback = Callback(on=\"train_epoch_end\", called_every=10, callback=callback_fn)\n",
    "\n",
    "config = TrainConfig(callbacks=[custom_callback])"
   ],
   "id": "2759e280b10aba28",
   "outputs": [],
   "execution_count": 4
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
